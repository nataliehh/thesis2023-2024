{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7344391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "annotation_path = './data/ILT_data/ILT_data_annotations.csv'\n",
    "df = pd.read_csv(annotation_path, index_col = 0)\n",
    "df['img'] = df['img'].astype('str') # Ensure that the data type of the image paths is string\n",
    "\n",
    "# Caption length is computed based on a crude tokenization of the caption\n",
    "df['caption_length'] = df['caption'].map(lambda x: len(re.split(r'[\\s,.]', x)))\n",
    "\n",
    "# Filtering\n",
    "df = df[df['caption_length'] >= 3] # filter out the shortest captions\n",
    "df = df[df['flag'] == False] # filter out flagged (=uncertain) annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a08887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than one label:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    92\n",
       "True     21\n",
       "Name: label_counts, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than two labels:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    112\n",
       "True       1\n",
       "Name: label_counts, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a value_count of the labels an image is assigned, and format it as [(label1, num_votes), (label2, num_votes), ...]\n",
    "df2 = df.groupby('img')['label'].agg([('label_counts', lambda x: ([(v, x.value_counts()[v]) for v in x.value_counts().keys()]))]).reset_index()\n",
    "\n",
    "# Check which images have more than one label related to them\n",
    "print('More than one label:')\n",
    "display(df2['label_counts'].map(lambda x: len(x) > 1).value_counts())\n",
    "# Check which images have more than two labels related to them\n",
    "print('More than two labels:')\n",
    "display(df2['label_counts'].map(lambda x: len(x) > 2).value_counts())\n",
    "\n",
    "\n",
    "# Take the most voted label as the best label for the image\n",
    "df2['best_label'] = df2['label_counts'].map(lambda x: max(x, key = lambda y: y[1])[0])\n",
    "# Drop the label counts since we don't need them anymore\n",
    "df2 = df2.drop(['label_counts'], axis = 1)\n",
    "# Add the label of the image as a column to the original dataframe\n",
    "df_labeled = pd.merge(df, df2, on = 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7ca86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sea faring/inland shipping       34\n",
       "Waste storage/waste processor    23\n",
       "Miscellaneous                    20\n",
       "Eigenwerken/water engineering    18\n",
       "Airstrip/aviation                16\n",
       "Waste transport                   2\n",
       "Name: best_label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get non-duplicates of the images, and count their labels\n",
    "df_unique = df_labeled.drop_duplicates(subset=['img'])\n",
    "df_unique['best_label'].value_counts() # 'Waste transportation' is only used twice, very rare label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b127f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Waste transport', which is very infrequent, with a related common label\n",
    "df_labeled['best_label'] = df_labeled['best_label'].replace('Waste transport', 'Waste storage/waste processor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d87d973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sea faring/inland shipping       34\n",
       " Waste storage/waste processor    25\n",
       " Miscellaneous                    20\n",
       " Eigenwerken/water engineering    18\n",
       " Airstrip/aviation                16\n",
       " Name: best_label, dtype: int64,\n",
       " (223, 11))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distributions of labels after replacing the infrequent label\n",
    "df_labeled.drop_duplicates(subset=['img'])['best_label'].value_counts(), df_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc1f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num images: 113 \tNum labels: 113\n",
      "train size: 67\t val size: 23\t test size: 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "images = df_labeled['img'].unique().tolist()\n",
    "labels = []\n",
    "for img in images:\n",
    "    label = df_labeled[df_labeled['img']==img]['best_label'].tolist()[0]\n",
    "    labels.append(label)\n",
    "\n",
    "print('Num images:', len(images), '\\tNum labels:', len(labels))\n",
    "X, y = images, labels\n",
    "\n",
    "train_size, val_size = 0.6, 0.2 # Specify train, val sizes\n",
    "test_size = round(1-val_size/(1 - train_size), 1) # Compute how large the test set is from the other sizes\n",
    "# print(test_size)\n",
    "\n",
    "# First split into a train split and the rest (i.e. val and test split together)\n",
    "train_X, val_test_X, train_y, val_test_y = train_test_split(X, y, stratify = y, train_size = train_size, random_state = 42)\n",
    "\n",
    "# Split the val-test split into their own splits\n",
    "if val_size == 0.0:\n",
    "    val_X, val_y = [], []\n",
    "    test_X, test_y = val_test_X, val_test_y\n",
    "else:\n",
    "    val_X, test_X, val_y, test_y = train_test_split(val_test_X, val_test_y, stratify = val_test_y, test_size =  test_size, \n",
    "                                                random_state = 42)\n",
    "print(f'train size: {len(train_X)}\\t val size: {len(val_X)}\\t test size: {len(test_X)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9fb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # set seed for reproducibility\n",
    "\n",
    "# Make a dataset dictionary in a similar format to the other (remote sensing) datasets\n",
    "ilt_dict = {'dataset': 'ILT', 'images': []}\n",
    "\n",
    "# Get a list of all the images (without duplicates)\n",
    "image_paths  = df_labeled['img'].unique().tolist()\n",
    "for abs_image_path in image_paths:\n",
    "    # Convert absolute image path to relative path for some more flexibility \n",
    "    # To do this, we remove all the folders on the path except the thematic folder + image filename\n",
    "    image_path = '\\\\'.join(abs_image_path.split('/')[-2:])\n",
    "    \n",
    "    # Filter for the part of the dataframe where the image path matches the current one\n",
    "    image_df = df_labeled[df_labeled['img'] == abs_image_path]\n",
    "    image_label = image_df['best_label'].tolist()[0]\n",
    "    image_captions = image_df['caption'].tolist()\n",
    "    \n",
    "    # Remove captions that are empty/only a whitespace\n",
    "    image_captions = [c for c in image_captions if c != ' ' and len(c) != 0]\n",
    "    if len(image_captions) == 0:\n",
    "        print('empty set of captions found, skipping')\n",
    "        continue\n",
    "        \n",
    "    # Get rid of some known spelling errors and remove unfinished parts from captions\n",
    "    image_captions = '\\t'.join(image_captions + [''])\n",
    "    replace_dict = {'casrs': 'cars', 'beign': 'being', 'surrouned': 'surrounded', 'safety chords': 'safety cords', \n",
    "                   'coupl ': 'couple ', 'some container ': 'some containers ', 'hazourdous': 'hazardous', \n",
    "                   'surrounde ': 'surrounded ', 'with sand an truck tracks': 'with sand and truck tracks', \n",
    "                   'arial': 'aerial', 'areial': 'aerial', ' or \\t': '', ' or\\t': '', ' and\\t': '', ' and \\t': ''}\n",
    "    for to_replace in replace_dict:\n",
    "        replacement = replace_dict[to_replace]\n",
    "        image_captions = image_captions.replace(to_replace, replacement)\n",
    "    image_captions = image_captions.split('\\t')[:-1]\n",
    "    \n",
    "    # Check the image path splits to determine the split of this specific image (based on its path)\n",
    "    split = 'train' if abs_image_path in train_X else 'val' if abs_image_path in val_X else 'test'\n",
    "    \n",
    "    # Keep track of all the relevant information about the image\n",
    "    image_label = image_label.replace('Eigenwerken/', '')\n",
    "    image_info = {'filename': image_path, 'label': image_label, 'captions': image_captions, 'split': split}\n",
    "\n",
    "    ilt_dict['images'].append(image_info) # Add the image info to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bffcb7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_path = './data/ILT_data/dataset.json'\n",
    "with open(data_info_path, 'w') as f:\n",
    "    json.dump(ilt_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6206b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_lst =  sorted(set([c['label'] for c in ilt_dict['images']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847120f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split label counts\n",
      "Counter({'Sea faring/inland shipping': 20, 'Waste storage/waste processor': 15, 'Miscellaneous': 12, 'water engineering': 11, 'Airstrip/aviation': 9})\n",
      "Validation split label counts\n",
      "Counter({'Sea faring/inland shipping': 7, 'Waste storage/waste processor': 5, 'water engineering': 4, 'Miscellaneous': 4, 'Airstrip/aviation': 3})\n",
      "Test split label counts\n",
      "Counter({'Sea faring/inland shipping': 7, 'Waste storage/waste processor': 5, 'Miscellaneous': 4, 'Airstrip/aviation': 4, 'water engineering': 3})\n",
      "All splits label counts\n",
      "Counter({'Sea faring/inland shipping': 34, 'Waste storage/waste processor': 25, 'Miscellaneous': 20, 'water engineering': 18, 'Airstrip/aviation': 16})\n"
     ]
    }
   ],
   "source": [
    "# Check how many times each label occurs per split, and in total\n",
    "train_labels = [c['label'] for c in ilt_dict['images'] if c['split'] == 'train']\n",
    "val_labels = [c['label'] for c in ilt_dict['images'] if c['split'] == 'val']\n",
    "test_labels = [c['label'] for c in ilt_dict['images'] if c['split'] == 'test']\n",
    "all_labels = [c['label'] for c in ilt_dict['images']]\n",
    "print(f'Train split label counts\\n{Counter(train_labels)}')\n",
    "print(f'Validation split label counts\\n{Counter(val_labels)}')\n",
    "print(f'Test split label counts\\n{Counter(test_labels)}')\n",
    "print(f'All splits label counts\\n{Counter(all_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ee60cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water engineering & 18 \\\\ \\hline\n",
      "Sea faring/inland shipping & 34 \\\\ \\hline\n",
      "Waste storage/waste processor & 25 \\\\ \\hline\n",
      "Airstrip/aviation & 16 \\\\ \\hline\n",
      "Miscellaneous & 20 \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "# Format for LateX\n",
    "label_counts = Counter(all_labels)\n",
    "for label in label_counts:\n",
    "    print(f'{label} & {label_counts[label]} \\\\\\\\ \\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75429c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': 'eigenwerken\\\\DJI_0060.JPG', 'label': 'water engineering', 'captions': ['a construction site around a river and some yellow floating deposit in the river and some boats with an excavator. ', 'construction site of a lock between a canal and the sea'], 'split': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Print example of how the data dictionary looks\n",
    "for item in ilt_dict['images']:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205706c1",
   "metadata": {},
   "source": [
    "# Image resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e2f14c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints 0\n",
      "afvalhopen 200\n",
      "eigenwerken 20\n",
      "luchtvaart 20\n",
      "overig 30\n",
      "schepen 187\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "ilt_data_path = './data/ILT_data/images/' # original data folder\n",
    "resized_path = './data/ILT_data/images_resized' # folder for resized images\n",
    "os.makedirs(resized_path, exist_ok = True) # make sure the folder for resized images exists\n",
    "folders = os.listdir(ilt_data_path) # list the image folders \n",
    "\n",
    "# Keep track of the image dimensions\n",
    "img_dims, new_img_dims = [], []\n",
    "\n",
    "target_h = 224 # Target height for the resized images\n",
    "\n",
    "# Loop over the images folders in the original data folder\n",
    "for folder in folders:\n",
    "    # Make a folder in the resized map\n",
    "    os.makedirs(os.path.join(resized_path, folder), exist_ok = True)\n",
    "    # Get the images in the original folder\n",
    "    folder_path = os.path.join(ilt_data_path, folder)\n",
    "    folder_contents = os.listdir(folder_path)\n",
    "    # Loop over the content (i.e. images) in the image folder\n",
    "    for content in folder_contents:\n",
    "        content_path = os.path.join(folder_path, content)\n",
    "        \n",
    "        # Get the image and its dimensions\n",
    "        img = Image.open(content_path)\n",
    "        img_w, img_h = img.size\n",
    "        \n",
    "        # Compute how the width has to be scaled, based on the target height \n",
    "        ratio = target_h/img_h\n",
    "        new_img_w = round(img_w * ratio)\n",
    "        \n",
    "        # Resize the image and store it in the folder for resized images\n",
    "        img_resized = img.resize((new_img_w, target_h), Image.Resampling.LANCZOS)\n",
    "        img_resized.save(os.path.join(resized_path, folder, content))\n",
    "        \n",
    "        # Store the dimensions of the original and resized image\n",
    "        img_dims.append(img.size)\n",
    "        new_img_dims.append(img_resized.size)\n",
    "    print(folder, len(folder_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211eff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(1296, 972): 198, (1000, 750): 120, (1014, 760): 40, (1013, 760): 32, (1000, 562): 30, (960, 540): 13, (2000, 1500): 10, (1368, 912): 7, (1296, 729): 5, (1013, 759): 1, (480, 270): 1})\n",
      "Counter({(299, 224): 401, (399, 224): 30, (398, 224): 19, (336, 224): 7})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(img_dims))\n",
    "print(Counter(new_img_dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e6bd9",
   "metadata": {},
   "source": [
    "# Keywords for S-CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9941c1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['waste storage', 'waste processor', 'water engineering', 'miscellaneous', 'airstrip', 'aviation', 'sea faring', 'inland shipping']\n"
     ]
    }
   ],
   "source": [
    "# S-CLIP saves keywords in the keywords folder, with subfolders per dataset\n",
    "os.makedirs('keywords', exist_ok = True)\n",
    "os.makedirs('./keywords/ILT', exist_ok = True)\n",
    "# Get the labels\n",
    "labels_unique = set(all_labels)\n",
    "# print(labels_unique)\n",
    "label_keywords = []\n",
    "# Split on the forward slash, e.g. \"a/b\" -> \"a\", \"b\"\n",
    "for label in labels_unique:\n",
    "    label_keywords.extend([l.lower() for l in label.split('/')])\n",
    "print(label_keywords)\n",
    "# Save in keywords file\n",
    "with open('./keywords/ILT/class-name.txt', 'w') as f:\n",
    "    f.write('\\n'.join(label_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651b706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
