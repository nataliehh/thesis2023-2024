{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7344391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "annotation_path = './data/ILT_data/ILT_data_annotations.csv'\n",
    "df = pd.read_csv(annotation_path, index_col = 0)\n",
    "df['img'] = df['img'].astype('str') # Ensure that the data type of the image paths is string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a08887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    70\n",
       "True     28\n",
       "Name: label_counts, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    97\n",
       "True      1\n",
       "Name: label_counts, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a value_count of the labels an image is assigned, and format it as [(label1, num_votes), (label2, num_votes), ...]\n",
    "df2 = df.groupby('img')['label'].agg([('label_counts', lambda x: ([(v, x.value_counts()[v]) for v in x.value_counts().keys()]))]).reset_index()\n",
    "\n",
    "# Check which images have more than one label related to them\n",
    "display(df2['label_counts'].map(lambda x: len(x) > 1).value_counts())\n",
    "# Check which images have more than one label related to them\n",
    "display(df2['label_counts'].map(lambda x: len(x) > 2).value_counts())\n",
    "\n",
    "\n",
    "# Take the most voted label as the best label for the image\n",
    "df2['best_label'] = df2['label_counts'].map(lambda x: max(x, key = lambda y: y[1])[0])\n",
    "# Drop the label counts since we don't need them anymore\n",
    "df2 = df2.drop(['label_counts'], axis = 1)\n",
    "# Add the label of the image as a column to the original dataframe\n",
    "df_labeled = pd.merge(df, df2, on = 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7ca86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sea faring/inland shipping       27\n",
       "Miscellaneous                    22\n",
       "Eigenwerken/water engineering    16\n",
       "Waste storage/waste processor    16\n",
       "Airstrip/aviation                15\n",
       "Waste transport                   2\n",
       "Name: best_label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get non-duplicates of the images, and count their labels\n",
    "df_unique = df_labeled.drop_duplicates(subset=['img'])\n",
    "df_unique['best_label'].value_counts() # 'Waste transportation' is only used twice, very rare label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b127f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Waste transport', which is very infrequent, with a related common label\n",
    "df_labeled['best_label'] = df_labeled['best_label'].replace('Waste transport', 'Waste storage/waste processor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d87d973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sea faring/inland shipping       27\n",
       " Miscellaneous                    22\n",
       " Waste storage/waste processor    18\n",
       " Eigenwerken/water engineering    16\n",
       " Airstrip/aviation                15\n",
       " Name: best_label, dtype: int64,\n",
       " (195, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distributions of labels after replacing the infrequent label\n",
    "df_labeled.drop_duplicates(subset=['img'])['best_label'].value_counts(), df_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc1f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num images: 98 Num labels: 98\n",
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(58, 20, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "images = df_labeled['img'].unique().tolist()\n",
    "labels = []\n",
    "for img in images:\n",
    "    label = df_labeled[df_labeled['img']==img]['best_label'].tolist()[0]\n",
    "    labels.append(label)\n",
    "\n",
    "print('Num images:', len(images), 'Num labels:', len(labels))\n",
    "X, y = images, labels\n",
    "\n",
    "train_size, val_size = 0.6, 0.2 # Specify train, val sizes\n",
    "test_size = round(1-val_size/(1 - train_size), 1) # Compute how large the test set is from the other sizes\n",
    "print(test_size)\n",
    "\n",
    "# First split into a train split and the rest (i.e. val and test split together)\n",
    "train_X, val_test_X, train_y, val_test_y = train_test_split(X, y, stratify = y, train_size = train_size, random_state = 42)\n",
    "\n",
    "# Split the val-test split into their own splits\n",
    "if val_size == 0.0:\n",
    "    val_X, val_y = [], []\n",
    "    test_X, test_y = val_test_X, val_test_y\n",
    "else:\n",
    "    val_X, test_X, val_y, test_y = train_test_split(val_test_X, val_test_y, stratify = val_test_y, test_size =  test_size, \n",
    "                                                random_state = 42)\n",
    "len(train_X), len(val_X), len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9fb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # set seed for reproducibility\n",
    "\n",
    "# Make a dataset dictionary in a similar format to the other (remote sensing) datasets\n",
    "ilt_dict = {'dataset': 'ILT', 'images': []}\n",
    "\n",
    "# Get a list of all the images (without duplicates)\n",
    "image_paths  = df_labeled['img'].unique().tolist()\n",
    "for abs_image_path in image_paths:\n",
    "    # Convert absolute image path to relative path for some more flexibility \n",
    "    # To do this, we remove all the folders on the path except the thematic folder + image filename\n",
    "    image_path = '\\\\'.join(abs_image_path.split('/')[-2:])\n",
    "    \n",
    "    # Filter for the part of the dataframe where the image path matches the current one\n",
    "    image_df = df_labeled[df_labeled['img'] == abs_image_path]\n",
    "    image_label = image_df['best_label'].tolist()[0]\n",
    "    image_captions = image_df['caption'].tolist()\n",
    "    \n",
    "    # Check the image path splits to determine the split of this specific image (based on its path)\n",
    "    split = 'train' if abs_image_path in train_X else 'val' if abs_image_path in val_X else 'test'\n",
    "    \n",
    "    # Keep track of all the relevant information about the image\n",
    "    image_info = {'filename': image_path, 'label': image_label, 'captions': image_captions, 'split': split}\n",
    "\n",
    "    ilt_dict['images'].append(image_info) # Add the image info to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bffcb7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_path = './data/ILT_data/dataset.json'\n",
    "with open(data_info_path, 'w') as f:\n",
    "    json.dump(ilt_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6206b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_lst =  sorted(set([c['label'] for c in ilt_dict['images']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847120f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split label counts\n",
      "Counter({'Sea faring/inland shipping': 16, 'Miscellaneous': 13, 'Waste storage/waste processor': 11, 'Eigenwerken/water engineering': 9, 'Airstrip/aviation': 9})\n",
      "Validation split label counts\n",
      "Counter({'Miscellaneous': 5, 'Sea faring/inland shipping': 5, 'Waste storage/waste processor': 4, 'Eigenwerken/water engineering': 3, 'Airstrip/aviation': 3})\n",
      "Test split label counts\n",
      "Counter({'Sea faring/inland shipping': 6, 'Eigenwerken/water engineering': 4, 'Miscellaneous': 4, 'Airstrip/aviation': 3, 'Waste storage/waste processor': 3})\n",
      "All splits label counts\n",
      "Counter({'Sea faring/inland shipping': 27, 'Miscellaneous': 22, 'Waste storage/waste processor': 18, 'Eigenwerken/water engineering': 16, 'Airstrip/aviation': 15})\n"
     ]
    }
   ],
   "source": [
    "# Check how many times each label occurs per split, and in total\n",
    "train_labels = [c['label'] for c in ilt_dict['images'] if c['split'] == 'train']\n",
    "val_labels = [c['label'] for c in ilt_dict['images'] if c['split'] == 'val']\n",
    "test_labels = [c['label'] for c in ilt_dict['images'] if c['split'] == 'test']\n",
    "all_labels = [c['label'] for c in ilt_dict['images']]\n",
    "print(f'Train split label counts\\n{Counter(train_labels)}')\n",
    "print(f'Validation split label counts\\n{Counter(val_labels)}')\n",
    "print(f'Test split label counts\\n{Counter(test_labels)}')\n",
    "print(f'All splits label counts\\n{Counter(all_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75429c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': 'eigenwerken\\\\DJI_0060.JPG', 'label': 'Eigenwerken/water engineering', 'captions': ['a construction site around a river and some yellow floating deposit in the river and some boats with an excavator. ', 'construction site of a lock between a canal and the sea'], 'split': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Print example of how the data dictionary looks\n",
    "for item in ilt_dict['images']:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205706c1",
   "metadata": {},
   "source": [
    "# Image resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e2f14c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints 0\n",
      "afvalhopen 200\n",
      "eigenwerken 20\n",
      "luchtvaart 20\n",
      "overig 30\n",
      "schepen 187\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "ilt_data_path = './data/ILT_data/images/' # original data folder\n",
    "resized_path = './data/ILT_data/images_resized' # folder for resized images\n",
    "os.makedirs(resized_path, exist_ok = True) # make sure the folder for resized images exists\n",
    "folders = os.listdir(ilt_data_path) # list the image folders \n",
    "\n",
    "# Keep track of the image dimensions\n",
    "img_dims, new_img_dims = [], []\n",
    "\n",
    "target_h = 224 # Target height for the resized images\n",
    "\n",
    "# Loop over the images folders in the original data folder\n",
    "for folder in folders:\n",
    "    # Make a folder in the resized map\n",
    "    os.makedirs(os.path.join(resized_path, folder), exist_ok = True)\n",
    "    # Get the images in the original folder\n",
    "    folder_path = os.path.join(ilt_data_path, folder)\n",
    "    folder_contents = os.listdir(folder_path)\n",
    "    # Loop over the content (i.e. images) in the image folder\n",
    "    for content in folder_contents:\n",
    "        content_path = os.path.join(folder_path, content)\n",
    "        \n",
    "        # Get the image and its dimensions\n",
    "        img = Image.open(content_path)\n",
    "        img_w, img_h = img.size\n",
    "        \n",
    "        # Compute how the width has to be scaled, based on the target height \n",
    "        ratio = target_h/img_h\n",
    "        new_img_w = round(img_w * ratio)\n",
    "        \n",
    "        # Resize the image and store it in the folder for resized images\n",
    "        img_resized = img.resize((new_img_w, target_h), Image.Resampling.LANCZOS)\n",
    "        img_resized.save(os.path.join(resized_path, folder, content))\n",
    "        \n",
    "        # Store the dimensions of the original and resized image\n",
    "        img_dims.append(img.size)\n",
    "        new_img_dims.append(img_resized.size)\n",
    "    print(folder, len(folder_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "211eff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(1296, 972): 198, (1000, 750): 120, (1014, 760): 40, (1013, 760): 32, (1000, 562): 30, (960, 540): 13, (2000, 1500): 10, (1368, 912): 7, (1296, 729): 5, (1013, 759): 1, (480, 270): 1})\n",
      "Counter({(299, 224): 401, (399, 224): 30, (398, 224): 19, (336, 224): 7})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(img_dims))\n",
    "print(Counter(new_img_dims))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
