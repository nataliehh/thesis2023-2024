{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9517c26a-cecc-4363-97d4-4538aeacb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/vol/tensusers4/nhollain/thesis2023-2024/s_clip_scripts')\n",
    "sys.path.append('./scripts')\n",
    "sys.path.append('./probvlm')\n",
    "\n",
    "import itertools\n",
    "from main import main, format_checkpoint\n",
    "from params import parse_args\n",
    "import copy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tuning_tools import prep_str_args, evaluate_checkpoint    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fadeac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# To evaluate CLIP without fine-tuning it! Set to False to skip\n",
    "evaluate_baseline = False\n",
    "if evaluate_baseline:\n",
    "    evaluate_checkpoint(checkpoint_path = None, epoch = 0, split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99e8109-1b98-4d55-96b6-ba9d06db445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "results = []\n",
    "if os.path.exists('./eval.txt'):   \n",
    "    with open('./eval.txt', 'r') as f:\n",
    "        results = f.readlines()\n",
    "\n",
    "# Remove any non-result lines from the eval file, and split the lines on the tab character\n",
    "# (results have format: model_name\\tdataset_name\\tmetric_name\\tmetric_value)\n",
    "results = [r.replace('\\n','').split('\\t')[0] for r in results if '\\t' in r]\n",
    "model_names = results\n",
    "# Remove the timestamp from the model names, as well as the specific fold - rest of the name contains params\n",
    "model_names = ['-'.join(m.split('-')[2:]).split('-fold')[0] for m in model_names]\n",
    "model_names = dict(Counter(model_names))\n",
    "# Show which models are already present in eval.txt\n",
    "# model_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6311e1-c938-434d-9d14-04385c1347b0",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7eaa23-316d-4c09-847e-bdd9c30550a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of configs: 1\n"
     ]
    }
   ],
   "source": [
    "# Do a grid search on the parameters\n",
    "# NOTE: for active learning, save-freq should be set to 1\n",
    "base_str_args = ''' --train-data ILT\n",
    "--val-data ILT \n",
    "--zeroshot-frequency 5  \n",
    "--save-freq 1\n",
    "'''\n",
    "# --label-ratio 0.1\n",
    "# --active-learning\n",
    "# --keyword-path keywords/RS/class-name.txt\n",
    "\n",
    "# Dictionary of values to gridsearch for hyperparam tuning\n",
    "gridsearch_dict = {\n",
    "    '--epochs' : [25], #list(range(15,36,5)) if 'active-learning' in base_str_args else [35], #[10,15,20,25,30,35],\n",
    "    '--batch-size' : [64],\n",
    "#     '--al-iter': [1], #list(range(3,17,2)), #list(range(1,6,2)),\n",
    "#     '--al-epochs': [35],\n",
    "    '--label-ratio': [1.0], # 0.05, 0.1, 0.2, 0.4, 0.8,\n",
    "#     '--pl-method': ['hard.text'],\n",
    "}\n",
    "\n",
    "\n",
    "split = 'test'\n",
    "# The number of validation repetitions is very specifically chosen because we have 9 folds for the datasets!\n",
    "num_repeats = 5 if 'test' else 9\n",
    "num_evals = 20 # How many evaluations are done with evaluate(...) - KEEP THIS FIXED\n",
    "\n",
    "gridsearch_values = list(gridsearch_dict.values())\n",
    "gridsearch_keys = list(gridsearch_dict.keys())\n",
    "configs = list(itertools.product(*gridsearch_values))\n",
    "print('Number of configs:', len(configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f405aaa0-49e5-47ad-9ec2-0dadb0ae4522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--train-data', 'ILT', '--val-data', 'ILT', '--zeroshot-frequency', '5', '--save-freq', '1', '--epochs', '25', '--batch-size', '64', '--label-ratio', '1.0']\n",
      "Config number 0: 5 repeats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▋                                  | 25.2M/256M [00:06<00:56, 4.08MiB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:31\u001b[0m\n",
      "File \u001b[1;32mD:\\Jupyter_notebook\\Thesis2023-2024_notebook\\./scripts\\main.py:153\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    150\u001b[0m log_base_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mlogs, args\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    152\u001b[0m random_seed(args\u001b[38;5;241m.\u001b[39mseed, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 153\u001b[0m model, preprocess_train, preprocess_val \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model_and_transforms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43maug_cfg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maug_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m model \u001b[38;5;241m=\u001b[39m create_custom_model(args, model)  \u001b[38;5;66;03m# use custom model\u001b[39;00m\n\u001b[0;32m    159\u001b[0m random_seed(args\u001b[38;5;241m.\u001b[39mseed, args\u001b[38;5;241m.\u001b[39mrank)\n",
      "File \u001b[1;32md:\\program files (x86)\\python39\\lib\\site-packages\\open_clip\\factory.py:382\u001b[0m, in \u001b[0;36mcreate_model_and_transforms\u001b[1;34m(model_name, pretrained, precision, device, jit, force_quick_gelu, force_custom_text, force_patch_dropout, force_image_size, image_mean, image_std, image_interpolation, image_resize_mode, aug_cfg, pretrained_image, pretrained_hf, cache_dir, output_dict, **model_kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model_and_transforms\u001b[39m(\n\u001b[0;32m    359\u001b[0m         model_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    360\u001b[0m         pretrained: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    378\u001b[0m ):\n\u001b[0;32m    379\u001b[0m     force_preprocess_cfg \u001b[38;5;241m=\u001b[39m merge_preprocess_kwargs(\n\u001b[0;32m    380\u001b[0m         {}, mean\u001b[38;5;241m=\u001b[39mimage_mean, std\u001b[38;5;241m=\u001b[39mimage_std, interpolation\u001b[38;5;241m=\u001b[39mimage_interpolation, resize_mode\u001b[38;5;241m=\u001b[39mimage_resize_mode)\n\u001b[1;32m--> 382\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_model(\n\u001b[0;32m    383\u001b[0m         model_name,\n\u001b[0;32m    384\u001b[0m         pretrained,\n\u001b[0;32m    385\u001b[0m         precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[0;32m    386\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    387\u001b[0m         jit\u001b[38;5;241m=\u001b[39mjit,\n\u001b[0;32m    388\u001b[0m         force_quick_gelu\u001b[38;5;241m=\u001b[39mforce_quick_gelu,\n\u001b[0;32m    389\u001b[0m         force_custom_text\u001b[38;5;241m=\u001b[39mforce_custom_text,\n\u001b[0;32m    390\u001b[0m         force_patch_dropout\u001b[38;5;241m=\u001b[39mforce_patch_dropout,\n\u001b[0;32m    391\u001b[0m         force_image_size\u001b[38;5;241m=\u001b[39mforce_image_size,\n\u001b[0;32m    392\u001b[0m         force_preprocess_cfg\u001b[38;5;241m=\u001b[39mforce_preprocess_cfg,\n\u001b[0;32m    393\u001b[0m         pretrained_image\u001b[38;5;241m=\u001b[39mpretrained_image,\n\u001b[0;32m    394\u001b[0m         pretrained_hf\u001b[38;5;241m=\u001b[39mpretrained_hf,\n\u001b[0;32m    395\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    396\u001b[0m         output_dict\u001b[38;5;241m=\u001b[39moutput_dict,\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[0;32m    400\u001b[0m     pp_cfg \u001b[38;5;241m=\u001b[39m PreprocessCfg(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvisual\u001b[38;5;241m.\u001b[39mpreprocess_cfg)\n\u001b[0;32m    402\u001b[0m     preprocess_train \u001b[38;5;241m=\u001b[39m image_transform_v2(\n\u001b[0;32m    403\u001b[0m         pp_cfg,\n\u001b[0;32m    404\u001b[0m         is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    405\u001b[0m         aug_cfg\u001b[38;5;241m=\u001b[39maug_cfg,\n\u001b[0;32m    406\u001b[0m     )\n",
      "File \u001b[1;32md:\\program files (x86)\\python39\\lib\\site-packages\\open_clip\\factory.py:201\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(model_name, pretrained, precision, device, jit, force_quick_gelu, force_custom_text, force_patch_dropout, force_image_size, force_preprocess_cfg, pretrained_image, pretrained_hf, cache_dir, output_dict, require_pretrained, **model_kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrained \u001b[38;5;129;01mand\u001b[39;00m pretrained\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    200\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading pretrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from OpenAI.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 201\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_openai_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     model_cfg \u001b[38;5;241m=\u001b[39m model_cfg \u001b[38;5;129;01mor\u001b[39;00m get_model_config(model_name)\n",
      "File \u001b[1;32md:\\program files (x86)\\python39\\lib\\site-packages\\open_clip\\openai.py:56\u001b[0m, in \u001b[0;36mload_openai_model\u001b[1;34m(name, precision, device, cache_dir)\u001b[0m\n\u001b[0;32m     53\u001b[0m     precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp32\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_pretrained_url(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 56\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_pretrained_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_pretrained_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenai\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(name):\n\u001b[0;32m     58\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[1;32md:\\program files (x86)\\python39\\lib\\site-packages\\open_clip\\pretrained.py:494\u001b[0m, in \u001b[0;36mdownload_pretrained_from_url\u001b[1;34m(url, cache_dir)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(source\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m\"\u001b[39m)), ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miB\u001b[39m\u001b[38;5;124m'\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 494\u001b[0m         buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buffer:\n\u001b[0;32m    496\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\program files (x86)\\python39\\lib\\http\\client.py:455\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 455\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32md:\\program files (x86)\\python39\\lib\\http\\client.py:499\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    494\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32md:\\program files (x86)\\python39\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\program files (x86)\\python39\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32md:\\program files (x86)\\python39\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for c, config in enumerate(configs): # Gridsearch\n",
    "    str_args = copy.deepcopy(base_str_args)\n",
    "    # Add the gridsearch parameters to the arguments\n",
    "    for i, param in enumerate(config):\n",
    "        param_name = gridsearch_keys[i]\n",
    "        str_args += '\\n{} {}'.format(param_name, param)\n",
    "        \n",
    "    str_args = prep_str_args(str_args)\n",
    "    print(str_args)\n",
    "    args = parse_args(str_args)\n",
    "    checkpoint_hypothetical = format_checkpoint(args)\n",
    "    # Remove the timestamp from the hypothetical checkpoint, so we can compare to the params of other checkpoints\n",
    "    checkpoint_params = '-'.join(checkpoint_hypothetical.split('-')[2:]).split('-fold')[0]\n",
    "\n",
    "    # Check if we've already trained the exact same model, correct the number of training iterations we still need to do\n",
    "    if checkpoint_params in model_names:\n",
    "        # The number of times to repeat depends on how often the model's been evaluated already\n",
    "        start_repeat = int(model_names[checkpoint_params]/num_evals)\n",
    "    else: # If we've never trained + evaluated the model before, just use num_repeats\n",
    "        start_repeat = 0\n",
    "    print('Config number {}: {} repeats'.format(c, max(0,num_repeats-start_repeat)))\n",
    "    for i in range(start_repeat, num_repeats):\n",
    "        # print('repeat number', i) \n",
    "        args = parse_args(str_args)\n",
    "        args.k_fold = i\n",
    "        # We compute here for which epochs we need to evaluate (based on for which epochs we checkpoint)\n",
    "        epoch_freq = args.save_freq\n",
    "        epochs = list(range(epoch_freq,args.epochs+1,epoch_freq))\n",
    "        # print('Epochs to checkpoint', epochs)\n",
    "        # print('Args k fold (outside):' , args.k_fold)\n",
    "        checkpoint_path = main(args) # Calls the main.py function of S-CLIP\n",
    "        for epoch in epochs:\n",
    "            evaluate(checkpoint_path, epoch = epoch, kfold = i, split = split)\n",
    "        # Remove the checkpoint after evaluating, to save space\n",
    "        os.system(\"rm -r {}\".format(checkpoint_path))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4b79f-34b8-43ce-b5a0-e4cd20d58d28",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21839599-a8c4-4936-8122-039e0b063b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = False\n",
    "\n",
    "if fashion:\n",
    "    str_args = '''--train-data Fashion-ALL\n",
    "            --label-ratio 0.1\n",
    "            --val-data Fashion-ALL\n",
    "            --keyword-path keywords/fashion/class-name.txt\n",
    "            --epochs 10\n",
    "            --method base  \n",
    "    '''\n",
    "else:\n",
    "    str_args = ''' --train-data RS-ALL\n",
    "            --label-ratio 0.1\n",
    "            --val-data RS-ALL\n",
    "            --imagenet-val RSICD-CLS \\\n",
    "            --keyword-path keywords/RS/class-name.txt\n",
    "            --epochs 5\n",
    "            --lr 5e-5\n",
    "            --zeroshot-frequency 5  \n",
    "            --method base\n",
    "            --active-learning\n",
    "            --al-iter 3\n",
    "    '''\n",
    "           # --active-learning\n",
    "        # --al-iter 3\n",
    "\n",
    "# Convert string arguments to a format that can be parsed by parse_args             \n",
    "str_args = prep_str_args(str_args)\n",
    "args = parse_args(str_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e9538-7246-4ed0-986f-42336bf8b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# checkpoint_path = main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5d79c-3fbb-4e0b-996a-5c2556d12122",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1218276-2fe6-40ec-a825-31cc54c0027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# evaluate(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff853d9-f270-4443-9e6f-a98def1b60e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
