{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a91316-40b3-4026-9998-aaf594efc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# subprocess.call(['sh', './train.sh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4b79f-34b8-43ce-b5a0-e4cd20d58d28",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9517c26a-cecc-4363-97d4-4538aeacb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from s_clip_scripts.main import main\n",
    "from s_clip_scripts.params import parse_args\n",
    "\n",
    "fashion = True\n",
    "\n",
    "if fashion:\n",
    "    str_args = '''--model RN50 \n",
    "            --pretrained openai \n",
    "            --train-data Fashion-ALL\n",
    "            --label-ratio 0.1\n",
    "            --val-data Fashion-ALL\n",
    "            --keyword-path keywords/fashion/class-name.txt\n",
    "            --lr 5e-5 \n",
    "            --batch-size 64 \n",
    "            --warmup 10 \n",
    "            --epochs 10\n",
    "            --precision amp \n",
    "            --method base \n",
    "            --seed 0 \n",
    "    '''\n",
    "else:\n",
    "    str_args = '''--model RN50 \n",
    "            --pretrained openai \n",
    "            --train-data RS-ALL\n",
    "            --label-ratio 0.1\n",
    "            --val-data RS-ALL\n",
    "            --imagenet-val RSICD-CLS \\\n",
    "            --keyword-path keywords/RS/class-name.txt\n",
    "            --lr 5e-5 \n",
    "            --batch-size 64 \n",
    "            --warmup 10 \n",
    "            --epochs 25\n",
    "            --zeroshot-frequency 5 \n",
    "            --precision amp \n",
    "            --method base \n",
    "            --seed 0 \n",
    "    '''\n",
    "str_args = str_args.split('\\n')\n",
    "str_args = [s.strip() for s in str_args]\n",
    "str_args = [s.split(' ') for s in str_args]\n",
    "str_args = list(chain(*str_args))\n",
    "str_args = [s for s in str_args if len(s) > 0]\n",
    "args = parse_args(str_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451e9538-7246-4ed0-986f-42336bf8b6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making log path: 2023_10_12-09_47_28-data_Fashion-ALL-ratio_0.1-model_RN50-method_base-keyword_none-seed_0\n",
      "Running with a single process. Device cuda:0.\n",
      "Getting data...\n",
      "Fashion-ALL\n",
      "Fashion-ALL\n",
      "Data got.\n",
      "Start epoch 0\n",
      "Done training.\n",
      "Done evaluating.\n",
      "Start epoch 1\n",
      "Done training.\n",
      "Done evaluating.\n",
      "Start epoch 2\n",
      "Done training.\n",
      "Done evaluating.\n",
      "Start epoch 3\n",
      "Done training.\n",
      "Done evaluating.\n",
      "Start epoch 4\n",
      "Done training.\n",
      "Done evaluating.\n",
      "Start epoch 5\n",
      "Done training.\n",
      "Done evaluating.\n",
      "Start epoch 6\n",
      "Done training.\n",
      "Done evaluating.\n",
      "Start epoch 7\n",
      "Done training.\n",
      "Done evaluating.\n",
      "Start epoch 8\n",
      "Done training.\n",
      "Done evaluating.\n",
      "Start epoch 9\n",
      "Done training.\n",
      "Done evaluating.\n",
      "CPU times: user 3h 9min 19s, sys: 2min 26s, total: 3h 11min 46s\n",
      "Wall time: 42min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "main(args) # Calls the main.py function of S-CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5d79c-3fbb-4e0b-996a-5c2556d12122",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1218276-2fe6-40ec-a825-31cc54c0027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a single process. Device cuda:0.\n",
      "=> resuming checkpoint '2023_10_12-09_47_28-data_Fashion-ALL-ratio_0.1-model_RN50-method_base-keyword_none-seed_0/checkpoints/epoch_latest.pt' (epoch 10)\n",
      "Getting data...\n",
      "Fashion200k-SUBCLS\n",
      "['blazers and suit jackets', 'blouses', 'cargo pants', 'casual and day dresses', 'casual jackets', 'cocktail dresses', 'cropped pants', 'denim jackets', 'full length pants', 'fur jackets', 'gowns', 'harem pants', 'knee length skirts', 'leather jackets', 'leggings', 'long sleeved tops', 'maxi and long dresses', 'maxi skirts', 'mid length skirts', 'mini and short dresses', 'mini skirts', 'padded and down jackets', 'prom and formal dresses', 'shirts', 'short sleeve tops', 'skinny pants', 'sleeveless and tank tops', 'straight-leg pants', 't-shirts', 'waistcoats and gilets', 'wide-leg and palazzo pants']\n",
      "Data got.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 38.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29824/29824 [03:29<00:00, 142.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a single process. Device cuda:0.\n",
      "=> resuming checkpoint '2023_10_12-09_47_28-data_Fashion-ALL-ratio_0.1-model_RN50-method_base-keyword_none-seed_0/checkpoints/epoch_latest.pt' (epoch 10)\n",
      "Getting data...\n",
      "Fashion200k-CLS\n",
      "['dresses', 'jackets', 'pants', 'skirts', 'tops']\n",
      "Data got.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 78.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29824/29824 [03:26<00:00, 144.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a single process. Device cuda:0.\n",
      "=> resuming checkpoint '2023_10_12-09_47_28-data_Fashion-ALL-ratio_0.1-model_RN50-method_base-keyword_none-seed_0/checkpoints/epoch_latest.pt' (epoch 10)\n",
      "Getting data...\n",
      "FashionGen-CLS\n",
      "['backpacks', 'bag accessories', 'belts & suspenders', 'blankets', 'boots', 'briefcases', 'clutches & pouches', 'dresses', 'duffle & top handle bags', 'duffle bags', 'espadrilles', 'eyewear', 'fine jewelry', 'flats', 'gloves', 'hats', 'heels', 'jackets & coats', 'jeans', 'jewelry', 'jumpsuits', 'keychains', 'lace ups', 'lingerie', 'loafers', 'messenger bags', 'messenger bags & satchels', 'pants', 'pocket squares & tie bars', 'pouches & document holders', 'sandals', 'scarves', 'shirts', 'shorts', 'shoulder bags', 'skirts', 'sneakers', 'socks', 'suits & blazers', 'sweaters', 'swimwear', 'ties', 'tops', 'tote bags', 'underwear & loungewear']\n",
      "Data got.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 64.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 64/64 [00:01<00:00, 63.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a single process. Device cuda:0.\n",
      "=> resuming checkpoint '2023_10_12-09_47_28-data_Fashion-ALL-ratio_0.1-model_RN50-method_base-keyword_none-seed_0/checkpoints/epoch_latest.pt' (epoch 10)\n",
      "Getting data...\n",
      "FashionGen-SUBCLS\n",
      "['backpacks', 'bag accessories', 'belts & suspenders', 'blankets', 'boots', 'briefcases', 'clutches & pouches', 'dresses', 'duffle & top handle bags', 'duffle bags', 'espadrilles', 'eyewear', 'fine jewelry', 'flats', 'gloves', 'hats', 'heels', 'jackets & coats', 'jeans', 'jewelry', 'jumpsuits', 'keychains', 'lace ups', 'lingerie', 'loafers', 'messenger bags', 'messenger bags & satchels', 'pants', 'pocket squares & tie bars', 'pouches & document holders', 'sandals', 'scarves', 'shirts', 'shorts', 'shoulder bags', 'skirts', 'sneakers', 'socks', 'suits & blazers', 'sweaters', 'swimwear', 'ties', 'tops', 'tote bags', 'underwear & loungewear']\n",
      "Data got.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 78.71it/s]\n",
      "  0%|                                                                                                                                                               | 0/64 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/vol/tensusers5/nhollain/s_clip_scripts/data_loader.py\", line 301, in __getitem__\n    y = self.classes.index(cls_name)\nValueError: 'denim jackets' is not in list\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:13\u001b[0m\n",
      "File \u001b[0;32m/vol/tensusers5/nhollain/s_clip_scripts/main.py:241\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    239\u001b[0m writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mtrain_data:\n\u001b[0;32m--> 241\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/vol/tensusers5/nhollain/s_clip_scripts/evaluate.py:23\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, data, epoch, args, tb_writer)\u001b[0m\n\u001b[1;32m     20\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 23\u001b[0m zero_shot_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mzero_shot_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m metrics\u001b[38;5;241m.\u001b[39mupdate(zero_shot_metrics)\n\u001b[1;32m     26\u001b[0m autocast \u001b[38;5;241m=\u001b[39m get_autocast(args\u001b[38;5;241m.\u001b[39mprecision)\n",
      "File \u001b[0;32m/vol/tensusers5/nhollain/s_clip_scripts/evaluate.py:124\u001b[0m, in \u001b[0;36mzero_shot_eval\u001b[0;34m(model, data, epoch, args)\u001b[0m\n\u001b[1;32m    121\u001b[0m classifier \u001b[38;5;241m=\u001b[39m zero_shot_classifier(model, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassnames\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate\u001b[39m\u001b[38;5;124m\"\u001b[39m], args)\n\u001b[1;32m    123\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 124\u001b[0m top1, top5 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_zero_shot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzeroshot-val\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeroshot-val-top1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m top1\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/vol/tensusers5/nhollain/s_clip_scripts/zero_shot.py:41\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(model, classifier, dataloader, args)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     40\u001b[0m     top1, top5, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, unit_scale\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(d) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     43\u001b[0m             images, target \u001b[38;5;241m=\u001b[39m d\n",
      "File \u001b[0;32m/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/vol/tensusers5/nhollain/thesis_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/vol/tensusers5/nhollain/s_clip_scripts/data_loader.py\", line 301, in __getitem__\n    y = self.classes.index(cls_name)\nValueError: 'denim jackets' is not in list\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "checkpoint = '2023_10_12-09_47_28-data_Fashion-ALL-ratio_0.1-model_RN50-method_base-keyword_none-seed_0'\n",
    "# checkpoint = '2023_10_11-10_26_36-data_RS-ALL-ratio_0.1-model_RN50-method_base-keyword_none-seed_0'\n",
    "if 'Fashion' in checkpoint:\n",
    "    zeroshot_datasets = [\"Fashion200k-SUBCLS\", \"Fashion200k-CLS\", \"FashionGen-CLS\", \"FashionGen-SUBCLS\", \"Polyvore-CLS\", ]\n",
    "    retrieval_datasets = [\"FashionGen\", \"Polyvore\", \"Fashion200k\",]\n",
    "else:\n",
    "    zeroshot_datasets = [\"RSICD-CLS\", \"UCM-CLS\"] # \"WHU-RS19\", \"RSSCN7\", \"AID\" -> NOT WORKING bc of different data-loading workings\n",
    "    retrieval_datasets = [\"RSICD\", \"UCM\", \"Sydney\"]\n",
    "\n",
    "for dataset in zeroshot_datasets:\n",
    "    str_args = ['--name', checkpoint, '--imagenet-val', dataset]\n",
    "    args = parse_args(str_args)\n",
    "    main(args)\n",
    "\n",
    "for dataset in retrieval_datasets:\n",
    "    str_args = ['--name', checkpoint, '--val-data', dataset]\n",
    "    args = parse_args(str_args)\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff853d9-f270-4443-9e6f-a98def1b60e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
